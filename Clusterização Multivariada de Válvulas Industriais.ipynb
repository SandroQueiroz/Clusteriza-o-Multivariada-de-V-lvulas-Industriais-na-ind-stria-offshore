{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#carregar o dataset Lista_valvulas.xlsx"
      ],
      "metadata": {
        "id": "a2mNQvPTYl_Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-nO_O7TXQPZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Caminho do arquivo\n",
        "file_path = \"Lista_valvulas.xlsx\"\n",
        "\n",
        "# Carregar a planilha, ignorando a primeira linha (header=1)\n",
        "#xls = pd.excelFile(file_path, engine=\"openpyxl\")\n",
        "df = pd.read_excel(xls, sheet_name=xls.sheet_names[0], header=1, engine=\"openpyxl\")\n",
        "\n",
        "# Exibir informações básicas\n",
        "print(\"Linhas:\", len(df))\n",
        "print(\"Colunas:\", len(df.columns))\n",
        "print(\"Nome das colunas:\", df.columns.tolist()[:10])  # Mostra as 10 primeiras colunas\n",
        "print(df.head())  # Visualiza as primeiras linhas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Padronizar nomes de colunas"
      ],
      "metadata": {
        "id": "06zU_eN6YqoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------------\n",
        "# PASSO 1: Padronização dos nomes de colunas\n",
        "# - Coloca tudo em MAIÚSCULAS\n",
        "# - Remove quebras de linha e espaços duplicados\n",
        "# - Facilita o uso consistente dos campos ao longo do pipeline\n",
        "# ------------------------------------------------------------------------------------\n",
        "\n",
        "# Se o seu DataFrame já se chama df (carregado com header=1), aplique:\n",
        "df.columns = (\n",
        "    df.columns\n",
        "      .str.strip()               # remove espaços no início/fim\n",
        "      .str.replace(\"\\n\", \" \")    # substitui quebras de linha por espaço\n",
        "      .str.replace(\"  \", \" \")    # colapsa espaços duplicados\n",
        "      .str.upper()               # padroniza para maiúsculas\n",
        ")\n",
        "\n",
        "# Vamos inspecionar as 20 primeiras colunas para confirmar a padronização:\n",
        "print(\"Colunas (amostra):\", df.columns.tolist()[:20])\n",
        "print(\"Total de colunas:\", len(df.columns))\n",
        "print(\"Total de linhas:\", len(df))"
      ],
      "metadata": {
        "id": "F4uGg3bWXr8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checagens iniciais e perfil de nulos\n",
        "- realizar o primeiro diagnóstico de qualidade dos dados antes de qualquer normalização, clusterização ou modelagem"
      ],
      "metadata": {
        "id": "OeDLJZcVY4Zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ------------------------------------------------------------------------------------\n",
        "# PASSO 2: Perfil de nulos e tipo geral dos dados\n",
        "# - Quantifica nulos por coluna (para orientar limpeza posterior)\n",
        "# - Mostra tipos inferidos pelo pandas\n",
        "# ------------------------------------------------------------------------------------\n",
        "\n",
        "# Contagem de nulos por coluna (ordenada decrescente):\n",
        "null_count = df.isna().sum().sort_values(ascending=False)\n",
        "print(\"Nulos por coluna (top 20):\")\n",
        "print(null_count.head(20))\n",
        "\n",
        "# Tipos (dtypes) do pandas:\n",
        "print(\"\\nTipos inferidos pelo pandas:\")\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "s9iZnPdpYDUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remover colunas que não agregam ao dataset analítico inicial"
      ],
      "metadata": {
        "id": "ToJ-PHu2ZIN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cols_drop_safe = [\n",
        "    \"OID\",\n",
        "    \"PIPERUN_OID\",\n",
        "    \"PIPERUN_TAG\",\n",
        "    \"DESIGN_STATUS\",\n",
        "    \"VALVEWIZARD_SELECTED\",\n",
        "    \"VALVEWIZARD_INPUT\",\n",
        "    \"MECHANICS_REMARKS\",\n",
        "    \"PIPELINE_STATUS\",\n",
        "    \"COMPONENT_STATUS\"\n",
        "]\n",
        "\n",
        "# Filtra apenas as colunas que existem de fato no df (para evitar KeyError):\n",
        "exist_safe = [c for c in cols_drop_safe if c in df.columns]\n",
        "\n",
        "# Remoção:\n",
        "df = df.drop(columns=exist_safe)\n",
        "\n",
        "print(f\"Removidas (safe): {exist_safe}\")\n",
        "print(\"Colunas restantes:\", len(df.columns))"
      ],
      "metadata": {
        "id": "MMXcx4MkZRew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalização do diâmetro nominal\n",
        "- Converte representações como 1-1/2\", 3/4\", 10\" para float em polegadas (NPS)\n",
        "- Cria flag NPS_FLAG com faixa plausível (ajuste conforme necessidade)\n"
      ],
      "metadata": {
        "id": "MH9iDLaUbPcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def parse_nps(value):\n",
        "    \"\"\"\n",
        "    Converte '1-1/2\"', '3/4\"', '10\"', etc. em float (polegadas).\n",
        "    Retorna np.nan se não conseguir interpretar.\n",
        "    \"\"\"\n",
        "    if pd.isna(value):\n",
        "        return np.nan\n",
        "    s = str(value).strip()\n",
        "    s = s.replace('\"', '').replace(\"'\", '').replace(',', '.')\n",
        "    # padrão 'a-b/c'\n",
        "    m = re.match(r'^(\\d+)-(\\d+)/(\\d+)$', s)\n",
        "    if m:\n",
        "        a, b, c = m.groups()\n",
        "        try:\n",
        "            return float(a) + float(b)/float(c)\n",
        "        except Exception:\n",
        "            return np.nan\n",
        "    # limpar mantendo dígitos, ponto, barra e hífen\n",
        "    s2 = re.sub(r'[^0-9\\./-]', '', s)\n",
        "    # fração com hífen 'a-b/c'\n",
        "    if '/' in s2 and '-' in s2:\n",
        "        try:\n",
        "            base, frac = s2.split('-')\n",
        "            num, den = frac.split('/')\n",
        "            return float(base) + float(num)/float(den)\n",
        "        except Exception:\n",
        "            return np.nan\n",
        "    # fração simples 'b/c'\n",
        "    if '/' in s2 and '-' not in s2:\n",
        "        try:\n",
        "            num, den = s2.split('/')\n",
        "            return float(num)/float(den)\n",
        "        except Exception:\n",
        "            return np.nan\n",
        "    # número simples\n",
        "    try:\n",
        "        return float(s2)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "if \"VALV_DIAMETER_RAW\" in df.columns:\n",
        "    df[\"NPS_IN\"] = df[\"VALV_DIAMETER_RAW\"].apply(parse_nps)\n",
        "elif \"VALV_DIAMETER\" in df.columns:\n",
        "    df[\"NPS_IN\"] = df[\"VALV_DIAMETER\"].apply(parse_nps)\n",
        "\n",
        "# Faixa plausível (ajuste conforme o padrão de projeto): 0.25\" a 60\"\n",
        "if \"NPS_IN\" in df.columns:\n",
        "    df[\"NPS_FLAG\"] = np.where(df[\"NPS_IN\"].between(0.25, 60, inclusive=\"both\"),\n",
        "                              \"OK\", \"OUT_OF_RANGE\")"
      ],
      "metadata": {
        "id": "C2xpEvBSbKng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalização de temperaturas para float (°C) e coerência de faixa\n",
        "- Converte DESIGN_MIN_TEMP, OPER_NORM_TEMP, DESIGN_MAX_TEMP em *_NORM (float)\n",
        "- TEMP_RANGE_FLAG: 'OK' se min <= oper <= max; 'INCONSISTENT' caso contrário\n",
        "- TEMP_OUTLIER_FLAG: marca outliers amplos (ex.: min < -200°C ou max > 500°C)"
      ],
      "metadata": {
        "id": "Lb87rRT2btlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def to_float(series):\n",
        "    return pd.to_numeric(series, errors=\"coerce\")\n",
        "\n",
        "for c in [\"DESIGN_MIN_TEMP\", \"OPER_NORM_TEMP\", \"DESIGN_MAX_TEMP\"]:\n",
        "    src = f\"{c}_RAW\" if f\"{c}_RAW\" in df.columns else c\n",
        "    if src in df.columns:\n",
        "        df[f\"{c}_NORM\"] = to_float(df[src])\n",
        "\n",
        "# Coerência: min <= oper <= max (se todos existirem)\n",
        "required = [\"DESIGN_MIN_TEMP_NORM\",\"OPER_NORM_TEMP_NORM\",\"DESIGN_MAX_TEMP_NORM\"]\n",
        "if all(col in df.columns for col in required):\n",
        "    cond_ok = (\n",
        "        (df[\"DESIGN_MIN_TEMP_NORM\"].isna() |\n",
        "         df[\"OPER_NORM_TEMP_NORM\"].isna() |\n",
        "         df[\"DESIGN_MAX_TEMP_NORM\"].isna())\n",
        "        |\n",
        "        ((df[\"DESIGN_MIN_TEMP_NORM\"] <= df[\"OPER_NORM_TEMP_NORM\"]) &\n",
        "         (df[\"OPER_NORM_TEMP_NORM\"] <= df[\"DESIGN_MAX_TEMP_NORM\"]))\n",
        "    )\n",
        "    df[\"TEMP_RANGE_FLAG\"] = np.where(cond_ok, \"OK\", \"INCONSISTENT\")\n",
        "\n",
        "    # Outlier simples (ajuste conforme necessidade de engenharia)\n",
        "    df[\"TEMP_OUTLIER_FLAG\"] = np.where(\n",
        "        (df[\"DESIGN_MIN_TEMP_NORM\"] < -200) | (df[\"DESIGN_MAX_TEMP_NORM\"] > 500),\n",
        "        \"POTENTIAL_OUTLIER\", \"OK\"\n",
        "    )"
      ],
      "metadata": {
        "id": "GDDFO3rqbrAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalização da pressão máxima de projeto\n",
        "- Converte para bar em DESIGN_MAX_PRESS_BAR\n",
        "- Heurística: se valor >= 50.000, tratamos como Pa e dividimos por 100.000\n",
        "- PRESS_FLAG: 'OK' se 0.1 <= bar <= 1000; 'OUT_OF_RANGE' caso contrário"
      ],
      "metadata": {
        "id": "AOzqiYEZcPGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_bar(x):\n",
        "    val = pd.to_numeric(x, errors=\"coerce\")\n",
        "    if pd.isna(val):\n",
        "        return np.nan\n",
        "    # Heurística: valores grandes provavelmente em Pascal\n",
        "    return val / 1e5 if val >= 5e4 else val  # 100.000 Pa = 1 bar\n",
        "\n",
        "src_press = \"DESIGN_MAX_PRESS_RAW\" if \"DESIGN_MAX_PRESS_RAW\" in df.columns else \"DESIGN_MAX_PRESS\"\n",
        "if src_press in df.columns:\n",
        "    df[\"DESIGN_MAX_PRESS_BAR\"] = df[src_press].apply(to_bar)\n",
        "    df[\"PRESS_FLAG\"] = np.where(df[\"DESIGN_MAX_PRESS_BAR\"].between(0.1, 1000, inclusive=\"both\"),\n",
        "                                \"OK\", \"OUT_OF_RANGE\")"
      ],
      "metadata": {
        "id": "6m3of7yecLgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalização de vocabulário\n",
        "- TYPE_NORM: consolida sinônimos (ex.: 'BALL VALVE' -> 'BALL')\n",
        "- VALVE_APP_NORM: padroniza grafia e categorias\n",
        "- FLUID_CODE_NORM: padroniza para maiúsculas, sem espaços"
      ],
      "metadata": {
        "id": "ltoaHB_lcfXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapeamento de TYPE (ajuste conforme sua convenção interna)\n",
        "type_map = {\n",
        "    \"BALL VALVE\": \"BALL\",\n",
        "    \"BALL\": \"BALL\",\n",
        "    \"GLOBE VALVE\": \"GLOBE\",\n",
        "    \"GLOBE\": \"GLOBE\",\n",
        "    \"CHECK\": \"CHECK\",\n",
        "    \"NON-SLAM CHECK\": \"CHECK\",\n",
        "    \"GATE\": \"GATE\",\n",
        "    \"RELIEF VALVE PRESSURE\": \"PSV\",\n",
        "    \"BI OFFSET BUTTERFLY\": \"BUTTERFLY (DOUBLE OFFSET)\",\n",
        "    \"CONC BUTTERFLY\": \"BUTTERFLY (CONCENTRIC)\",\n",
        "    \"NEEDLE\": \"NEEDLE\",\n",
        "    \"DOUBLE BALL\": \"DOUBLE BALL\",\n",
        "}\n",
        "if \"TYPE\" in df.columns:\n",
        "    df[\"TYPE_NORM\"] = (\n",
        "        df[\"TYPE\"].astype(str).str.strip().str.upper()\n",
        "        .map(lambda x: type_map.get(x, x))\n",
        "    )\n",
        "\n",
        "# Mapeamento de VALVE_APPLICATION (exemplo; ajuste conforme seu padrão)\n",
        "app_map = {\n",
        "    \"PSV BLOCK OUTLET\": \"PSV BLOCK OUTLET\",\n",
        "    \"PSV BLOCK INLET\": \"PSV BLOCK INLET\",\n",
        "    \"PSV\": \"PSV\",\n",
        "    \"CHECK VALVE\": \"CHECK\",\n",
        "    \"XV\": \"XV\",\n",
        "    \"SDV\": \"SDV\",\n",
        "    \"BDV BLOCK\": \"BDV BLOCK\",\n",
        "    \"INSTRUMENT BLOCK\": \"INSTRUMENT BLOCK\",\n",
        "    \"LIT / LG BLOCK\": \"LEVEL BLOCK\",\n",
        "    \"DRAIN / UTILITY\": \"DRAIN/UTILITY\",\n",
        "    \"OTHER BLOCK\": \"OTHER BLOCK\",\n",
        "    \"MANUAL CONTROL\": \"MANUAL CONTROL\",\n",
        "}\n",
        "if \"VALVE_APPLICATION\" in df.columns:\n",
        "    df[\"VALVE_APP_NORM\"] = (\n",
        "        df[\"VALVE_APPLICATION\"].astype(str).str.strip().str.upper()\n",
        "        .map(lambda x: app_map.get(x, x))\n",
        "    )\n",
        "\n",
        "# FLUID_CODE → maiúsculas, sem espaços\n",
        "if \"FLUID_CODE\" in df.columns:\n",
        "    df[\"FLUID_CODE_NORM\"] = df[\"FLUID_CODE\"].astype(str).str.strip().str.upper()"
      ],
      "metadata": {
        "id": "zGsuhMa3cZMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Completude (campos críticos) e chave técnica composta\n",
        "- MISSING_FLAG: marca registros com ao menos 1 campo crítico nulo\n",
        "- KEY_TECH: concatena MODULE|TAG|PLANTGROUP para rastreabilidade técnica"
      ],
      "metadata": {
        "id": "9txI44iKc3R3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "critical_for_completeness = [\n",
        "    \"TYPE\",\"VALVE_APPLICATION\",\"FLUID_CODE\",\"VALV_DIAMETER\",\n",
        "    \"DESIGN_MAX_TEMP\",\"DESIGN_MIN_TEMP\",\"DESIGN_MAX_PRESS\",\n",
        "    \"TAG\",\"MODULE\",\"PLANTGROUP\"\n",
        "]\n",
        "critical_present = [c for c in critical_for_completeness if c in df.columns]\n",
        "\n",
        "if critical_present:\n",
        "    df[\"MISSING_FLAG\"] = np.where(df[critical_present].isna().any(axis=1), \"HAS_MISSING\", \"OK\")\n",
        "\n",
        "# Garantir existência das colunas de chave\n",
        "for c in [\"MODULE\",\"TAG\",\"PLANTGROUP\"]:\n",
        "    if c not in df.columns:\n",
        "        df[c] = np.nan\n",
        "\n",
        "df[\"KEY_TECH\"] = (\n",
        "    df[\"MODULE\"].astype(str).str.strip() + \"|\" +\n",
        "    df[\"TAG\"].astype(str).str.strip() + \"|\" +\n",
        "    df[\"PLANTGROUP\"].astype(str).str.strip()\n",
        ")"
      ],
      "metadata": {
        "id": "o09r_FUCcvRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLUSTERIZAÇÃO\n",
        "- Seleção de features e preparação (numéricos + categóricos)\n",
        "\n",
        "- Numéricos: NPS_IN, DESIGN_MAX_PRESS_BAR, DESIGN_MIN_TEMP_NORM, OPER_NORM_TEMP_NORM, DESIGN_MAX_TEMP_NORM\n",
        "- Categóricos (codificação one‑hot): TYPE_NORM, VALVE_APP_NORM, FLUID_CODE_NORM\n",
        "- Removidas linhas com nulos apenas nas colunas de features para evitar quebra do pipeline."
      ],
      "metadata": {
        "id": "CprxILt-dGNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Escolha das colunas de entrada (ajuste conforme necessário):\n",
        "num_features = [\n",
        "    \"NPS_IN\",\n",
        "    \"DESIGN_MAX_PRESS_BAR\",\n",
        "    \"DESIGN_MIN_TEMP_NORM\",\n",
        "    \"OPER_NORM_TEMP_NORM\",\n",
        "    \"DESIGN_MAX_TEMP_NORM\",\n",
        "]\n",
        "cat_features = [\n",
        "    \"TYPE_NORM\",\n",
        "    \"VALVE_APP_NORM\",\n",
        "    \"FLUID_CODE_NORM\",\n",
        "]\n",
        "\n",
        "# Filtra o DataFrame para conter somente as colunas de interesse\n",
        "available_num = [c for c in num_features if c in df.columns]\n",
        "available_cat = [c for c in cat_features if c in df.columns]\n",
        "X = df[available_num + available_cat].copy()\n",
        "\n",
        "# Remover linhas com nulos nas features (mínimo necessário para scikit-learn)\n",
        "X = X.dropna(subset=available_num)  # categóricas podem ter NaN, vamos preenchê-las no encoder\n",
        "print(f\"Registros disponíveis para clusterização: {len(X)}\")\n",
        "\n",
        "# Mantém índice original para mapear clusters de volta ao df principal\n",
        "idx_map = X.index"
      ],
      "metadata": {
        "id": "RqdGipi9dDs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLUSTERIZAÇÃO PASSO 2:\n",
        "- ColumnTransformer + Pipeline\n",
        "- Numéricos → StandardScaler (média=0, desvio=1).\n",
        "- Categóricos → OneHotEncoder (gera colunas binárias; usamos handle_unknown='ignore')."
      ],
      "metadata": {
        "id": "x2H7hJbod5_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------------------------------------------------------------\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Transformadores\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n",
        "\n",
        "# ColumnTransformer: combina ambos\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, available_num),\n",
        "        (\"cat\", categorical_transformer, available_cat),\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")"
      ],
      "metadata": {
        "id": "5xqQfd_Vd2y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baseline com K‑Means (escolha de k usando silhouette)\n",
        "\n",
        "- Testei alguns valores de k e escolhi aquele com melhor silhouette score.\n",
        "- Depois rodei K‑Means com o k escolhido e armazenei os rótulos no df."
      ],
      "metadata": {
        "id": "SA6X1j8ieSN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Lista de k para testar (ajuste conforme necessidade)\n",
        "candidate_k = [4, 5, 6, 7, 8]\n",
        "\n",
        "# Pré-processa os dados (escala + one-hot)\n",
        "X_transformed = preprocess.fit_transform(X)\n",
        "\n",
        "best_k = None\n",
        "best_score = -1\n",
        "scores = {}\n",
        "\n",
        "for k in candidate_k:\n",
        "    # n_init moderno usa 'auto' (sklearn>=1.4); se a versão for anterior, use n_init=10\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
        "    labels = km.fit_predict(X_transformed)\n",
        "    # Evitar silhouette com 1 cluster\n",
        "    score = silhouette_score(X_transformed, labels) if len(set(labels)) > 1 else -1\n",
        "    scores[k] = score\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_k = k\n",
        "\n",
        "print(\"Scores de silhouette por k:\", scores)\n",
        "print(\"Melhor k:\", best_k, \" | silhouette:\", round(best_score, 4))\n",
        "\n",
        "# Treina K-Means final com o melhor k\n",
        "km_final = KMeans(n_clusters=best_k, random_state=42, n_init=\"auto\")\n",
        "labels_km = km_final.fit_predict(X_transformed)\n",
        "\n",
        "# Persiste rótulos no df original\n",
        "df.loc[idx_map, \"CLUSTER_KMEANS\"] = labels_km\n",
        "\n",
        "# Centroides (no espaço transformado); para interpretação, podemos usar médias por cluster no espaço original\n",
        "centroids_transformed = km_final.cluster_centers_\n",
        "print(\"K-Means concluído. Clusters atribuídos em 'CLUSTER_KMEANS'.\")"
      ],
      "metadata": {
        "id": "lQH4EzDxeOMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Interpretação prática dos clusters - cluster_kmeans_summary.csv\n",
        "- Cálculo de médias e proporções das variáveis no espaço original\n",
        "- planilha gerada contém resumo por cluster do K‑Means, mostrando contagem, médias, mínimos e máximos das variáveis numéricas e os TOP valores categóricos (TYPE, FLUID).\n",
        "- Útil para interpretar cada cluster como um regime técnico (perfil de válvulas, condições de processo)."
      ],
      "metadata": {
        "id": "eUeyRoNDet2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cluster_summary = (\n",
        "    df.loc[idx_map, [\"CLUSTER_KMEANS\"] + available_num + available_cat]\n",
        "      .groupby(\"CLUSTER_KMEANS\")\n",
        "      .agg({\n",
        "          **{c: [\"count\", \"mean\", \"min\", \"max\"] for c in available_num},\n",
        "          **{c: lambda s: s.value_counts().head(3) for c in available_cat}\n",
        "      })\n",
        ")\n",
        "\n",
        "print(cluster_summary)\n",
        "# Opcional: salvar para consulta\n",
        "cluster_summary.to_csv(\"cluster_kmeans_summary.csv\")"
      ],
      "metadata": {
        "id": "ESSPoy4Be1_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DBSCAN (densidade + outliers)"
      ],
      "metadata": {
        "id": "8R9HC5f8fOoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# Pré-processamento (já feito acima): X_transformed\n",
        "# Parâmetros iniciais (ajuste conforme inspeção dos resultados):\n",
        "db = DBSCAN(eps=1.5, min_samples=40, n_jobs=-1)\n",
        "#eps = 1.2 a 2.0 e min_samples = 30 a 60 (valores ótimos)\n",
        "labels_db = db.fit_predict(X_transformed)\n",
        "\n",
        "# -1 indica outliers (ruído) no DBSCAN\n",
        "df.loc[idx_map, \"CLUSTER_DBSCAN\"] = labels_db\n",
        "\n",
        "# Quantitativo de clusters e outliers:\n",
        "unique_labels = pd.Series(labels_db).value_counts().sort_index()\n",
        "print(\"Clusters DBSCAN (inclui -1 = outliers):\")\n",
        "print(unique_labels)\n",
        "\n",
        "# Percentual de outliers:\n",
        "pct_outliers = (unique_labels.get(-1, 0) / len(labels_db)) * 100\n",
        "print(f\"Outliers (DBSCAN): {pct_outliers:.2f}%\")"
      ],
      "metadata": {
        "id": "Rzj88xatfE1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sumário dos grupos DBSCAN (excluindo outliers) - cluster_dbscan_summary.csv\n",
        "- Exclui o rótulo -1 (outliers) para sumarização\n",
        "- planilha gerada contém um resumo dos clusters densos encontrados pelo DBSCAN (exclui outliers), com estatísticas numéricas e TOP categorias por cluster.\n",
        "- Ajuda a entender regimes reais de operação e diferenciar grupos coerentes dos outliers detectados pelo modelo."
      ],
      "metadata": {
        "id": "4uqiAnJvgMxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "valid_mask = labels_db != -1\n",
        "dbscan_summary = (\n",
        "    df.loc[idx_map[valid_mask], [\"CLUSTER_DBSCAN\"] + available_num + available_cat]\n",
        "      .groupby(\"CLUSTER_DBSCAN\")\n",
        "      .agg({\n",
        "          **{c: [\"count\", \"mean\", \"min\", \"max\"] for c in available_num},\n",
        "          **{c: lambda s: s.value_counts().head(3) for c in available_cat}\n",
        "      })\n",
        ")\n",
        "\n",
        "print(dbscan_summary)\n",
        "dbscan_summary.to_csv(\"cluster_dbscan_summary.csv\")"
      ],
      "metadata": {
        "id": "43xZg2w6gJ4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exportar resultados (rótulos + perfis) - valves_clusters.csv\n",
        "dataset final do estudo, já normalizado, contendo:\n",
        "\n",
        "- Todos os dados tratados (NPS em polegadas, pressão em bar, temperaturas em °C);\n",
        "- As features usadas no modelo (numéricas + categóricas normalizadas);\n",
        "- Os rótulos dos modelos (CLUSTER_KMEANS e CLUSTER_DBSCAN);\n",
        "- As flags de qualidade (outliers, incoerências, nulos, faixas inválidas);\n",
        "- As colunas RAW vs NORMALIZADAS para rastreabilidade."
      ],
      "metadata": {
        "id": "M5psQziTgbO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# DataFrame com rótulos\n",
        "out = df.loc[idx_map, [\"TAG\",\"MODULE\",\"PLANTGROUP\"] + available_num + available_cat + [\"CLUSTER_KMEANS\",\"CLUSTER_DBSCAN\"]]\n",
        "out.to_csv(\"valves_clusters.csv\", index=False)\n",
        "print(\"Arquivo gerado: valves_clusters.csv (rótulos K-Means e DBSCAN).\")"
      ],
      "metadata": {
        "id": "uqE4iWAhgdqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Geração de tabela PCA (PC1 × PC2) para auxiliar na análise gráfica de múltiplas variáveis originais"
      ],
      "metadata": {
        "id": "vFBVwa_9Ab21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Carregar a base\n",
        "df = pd.read_csv(\"valves_clusters.csv\")\n",
        "\n",
        "# Selecionar somente variáveis numéricas usadas no clustering\n",
        "cols_num = [\n",
        "    \"NPS_IN\",\n",
        "    \"DESIGN_MAX_PRESS_BAR\",\n",
        "    \"DESIGN_MIN_TEMP_NORM\",\n",
        "    \"OPER_NORM_TEMP_NORM\",\n",
        "    \"DESIGN_MAX_TEMP_NORM\"\n",
        "]\n",
        "\n",
        "X = df[cols_num]\n",
        "\n",
        "# Normalização (igual ao pipeline do clustering)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# PCA — reduzindo para 2 dimensões\n",
        "pca = PCA(n_components=2)\n",
        "pcs = pca.fit_transform(X_scaled)\n",
        "\n",
        "df[\"PC1\"] = pcs[:, 0]\n",
        "df[\"PC2\"] = pcs[:, 1]\n",
        "#df[\"CLUSTER_DBSCAN\"] = (df[\"CLUSTER_DBSCAN\"] / 10).astype(int)\n",
        "\n",
        "# Mantém os clusters DBSCAN e KMeans\n",
        "df_pca = df[[\n",
        "    \"TAG\",\n",
        "    \"PC1\",\"PC2\",\n",
        "    \"CLUSTER_KMEANS\",\n",
        "    \"CLUSTER_DBSCAN\",\n",
        "    \"TYPE_NORM\",\n",
        "    \"VALVE_APP_NORM\",\n",
        "    \"FLUID_CODE_NORM\"\n",
        "]]\n",
        "#df[\"CLUSTER_DBSCAN\"] = (df[\"CLUSTER_DBSCAN\"] / 10).astype(int)\n",
        "df_pca.to_csv(\"pca_coords.csv\", index=False)\n",
        "print(\"Arquivo gerado: pca_coords.csv\")"
      ],
      "metadata": {
        "id": "l8fFBici73gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "typ4YyES-wCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "836bed6a"
      },
      "source": [
        "#Visualizações gráficas dos resultados\n",
        "\n",
        "#**K-means Raciocínio**:\n",
        "O cluster Kmeans não identifica outliers, ele força cada ponto a pertencer a um cluster, mesmo que seja um ponto completamente anormal, porém, visualmente, é possível identificar de forma clara valores distantes que se comportam como outliers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae9ea49d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(\n",
        "    x='PC1',\n",
        "    y='PC2',\n",
        "    hue='CLUSTER_KMEANS',\n",
        "    data=df_pca_coords,\n",
        "    palette='viridis',\n",
        "    legend='full'\n",
        ")\n",
        "plt.title('Clusters K-Means no Espaço PCA')\n",
        "plt.xlabel('Componente Principal 1 (PC1)')\n",
        "plt.ylabel('Componente Principal 2 (PC2)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DBSCAN Raciocínio:**\n",
        "\n",
        "O cluster DBSCAN separa os outliers (valor -1) pela cor azul escuro. O motivo pelo qual aparecem outliers dentro das nuvens de clusters é porque o PCA é apenas uma representação em duas dimensões de um espaço multidimensional. Sendo assim, o PCA “achata” o espaço e pode projetar um ponto distante em cima da nuvem"
      ],
      "metadata": {
        "id": "54EtNmQcU6xv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7e6aba7"
      },
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(\n",
        "    x='PC1',\n",
        "    y='PC2',\n",
        "    hue='CLUSTER_DBSCAN',\n",
        "    data=df_pca_coords,\n",
        "    palette='tab20', # Use a different palette for DBSCAN to distinguish from K-Means\n",
        "    legend='full'\n",
        ")\n",
        "plt.title('Clusters DBSCAN no Espaço PCA')\n",
        "plt.xlabel('Componente Principal 1 (PC1)')\n",
        "plt.ylabel('Componente Principal 2 (PC2)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc0e2a4e"
      },
      "source": [
        "**Raciocínio**:\n",
        "\n",
        "Os gráficos a seguir mostram a distribuição dos clusters pelas categorias \"Tipos de válvulas\", \"Aplicação\" e \"Tipos de fluidos\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "391a7d03"
      },
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(\n",
        "    x='PC1',\n",
        "    y='PC2',\n",
        "    hue='TYPE_NORM',\n",
        "    data=df_pca_coords,\n",
        "    palette='tab20',\n",
        "    legend='full'\n",
        ")\n",
        "plt.title('Distribuição por tipo de válvula no espaço PCA')\n",
        "plt.xlabel('Componente Principal 1 (PC1)')\n",
        "plt.ylabel('Componente Principal 2 (PC2)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0b20852"
      },
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "sns.scatterplot(\n",
        "    x='PC1',\n",
        "    y='PC2',\n",
        "    hue='VALVE_APP_NORM',\n",
        "    data=df_pca_coords,\n",
        "    palette='tab20',\n",
        "    legend='full'\n",
        ")\n",
        "plt.title('Distribuição por aplicação de válvulas no espaço PCA')\n",
        "plt.xlabel('componente principal 1 (PC1)')\n",
        "plt.ylabel('componente principal 2 (PC2)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "056b4ac1"
      },
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "sns.scatterplot(\n",
        "    x='PC1',\n",
        "    y='PC2',\n",
        "    hue='FLUID_CODE_NORM',\n",
        "    data=df_pca_coords,\n",
        "    palette='tab20',\n",
        "    legend='full'\n",
        ")\n",
        "plt.title('Distribuição por tipo de fluido no espaço PCA')\n",
        "plt.xlabel('componente principal 1 (PC1)')\n",
        "plt.ylabel('componente principal 2 (PC2)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------------------------ FIM ---------------------------------"
      ],
      "metadata": {
        "id": "i7a09MTuUDow"
      }
    }
  ]
}